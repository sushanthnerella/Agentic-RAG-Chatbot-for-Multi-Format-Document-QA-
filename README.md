# Agentic-RAG-Chatbot-for-Multi-Format-Document-QA-
# ğŸ“„ Agentic RAG Chatbot

A **multi-agent Retrieval-Augmented Generation (RAG) chatbot** capable of answering questions from multiple uploaded documents (PDF, DOCX, TXT, CSV, PPTX).

The system is built on a **FastAPI backend** (with 3 core agents) and a **Streamlit frontend** for user interaction. It uses **Google Gemini LLMs**, **ChromaDB vector store**, and a **Model Context Protocol (MCP)** for clean agent communication.

---

## ğŸš€ Features

* ğŸ“‚ Upload and process documents in multiple formats.
* ğŸ” Multi-query retrieval with re-ranking for **highly relevant answers**.
* ğŸ§  Agent-based architecture: Ingestion, Retrieval, and LLM Response.
* ğŸ’¬ Multi-turn, conversational interface (Streamlit).
* ğŸ—„ï¸ Persistent ChromaDB for embeddings.

---

## ğŸ—ï¸ Architecture

```
Frontend (Streamlit UI)  <â”€â”€>  FastAPI Backend
                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ CoordinatorAgent (main.py)                â”‚
         â”‚    â”œâ”€â”€ IngestionAgent: Parse & embed docs â”‚
         â”‚    â”œâ”€â”€ RetrievalAgent: Search & rerank    â”‚
         â”‚    â””â”€â”€ LLMResponseAgent: Generate answers â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Project Structure

```
/agentic-rag-chatbot/
â”œâ”€â”€ agentic_rag_backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â”‚   â””â”€â”€ llm_response_agent.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ chroma_db/
â”‚   â”œâ”€â”€ uploaded_files/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ streamlit_ui/
    â””â”€â”€ app.py
```

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/agentic-rag-chatbot.git
cd agentic-rag-chatbot
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r agentic_rag_backend/requirements.txt
```

### 4. Configure API Key

Create a `.env` file inside `agentic_rag_backend/` and add:

```
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
```

---

## â–¶ï¸ Running the Application

### Start the Backend (FastAPI)

```bash
cd agentic_rag_backend
uvicorn main:app --reload
```

### Start the Frontend (Streamlit)

```bash
cd streamlit_ui
streamlit run app.py
```

App will be available at **[http://localhost:8501](http://localhost:8501)**.

---

## ğŸ“˜ Usage

1. Upload documents from the **sidebar**.
2. Ask questions in the chatbox.
3. Get **answers with cited sources** from your uploaded files.

---

## ğŸ“Š Tech Stack

* **FastAPI** â€“ Backend API
* **Streamlit** â€“ Frontend UI
* **LangChain + Google Gemini** â€“ Embeddings & LLM responses
* **ChromaDB** â€“ Vector database
* **Python-dotenv** â€“ Environment configuration

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.

---

## ğŸ“œ License

This project is licensed under the MIT License.

---


# Agentic-RAG-Chatbot-for-Multi-Format-Document-QA-
